{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Slope Analysis: Selection Gradients in Multilayer Networks\n",
    "\n",
    "**Purpose**: Analyze θ,φ coefficients from enumeration to compute selection gradients  \n",
    "**Input**: CSV/Parquet from `Enumeration_N6.ipynb`  \n",
    "**Language**: Python 3.10+\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook analyzes the enumeration results to compute:\n",
    "\n",
    "1. **Selection gradients**: ∂r*/∂b = φ₂₀/θ₂ and ∂r*/∂c = (φ₀₁−φ₂₁)/θ₂\n",
    "2. **Sign classifications**: Distribution of configurations by sign(θ₁−θ₃) × sign(φ₀₁−φ₂₁)\n",
    "3. **Statistical aggregations**: By root positions, theta triplets, etc.\n",
    "4. **Visualizations**: Heatmaps, scatter plots, histograms\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "```bash\n",
    "pip install polars duckdb matplotlib numpy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Input data (from Enumeration_N6.ipynb)\n",
    "DATA_FILE = \"N6_enumeration.csv\"        # Or .parquet\n",
    "# DATA_FILE = \"N6_enumeration.parquet\"  # Faster for large files\n",
    "\n",
    "# Analysis parameters\n",
    "EPS = 1e-8  # Tolerance for sign classification\n",
    "\n",
    "# Output figures\n",
    "SAVE_FIGURES = True\n",
    "FIG_DPI = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import duckdb\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from pathlib import Path\n",
    "\n",
    "# Plotting style\n",
    "plt.rcParams.update({\n",
    "    'font.size': 11,\n",
    "    'axes.titlesize': 12,\n",
    "    'axes.labelsize': 11,\n",
    "    'figure.dpi': 100,\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Load Data\n",
    "\n",
    "Uses Polars LazyFrame for memory-efficient processing of large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath: str) -> pl.LazyFrame:\n",
    "    \"\"\"\n",
    "    Load enumeration data as a Polars LazyFrame.\n",
    "    \n",
    "    Supports both CSV and Parquet formats.\n",
    "    \"\"\"\n",
    "    path = Path(filepath)\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Data file not found: {filepath}\")\n",
    "    \n",
    "    if path.suffix == '.parquet':\n",
    "        lf = pl.scan_parquet(filepath)\n",
    "    else:\n",
    "        lf = pl.scan_csv(filepath)\n",
    "    \n",
    "    return lf\n",
    "\n",
    "# Load data\n",
    "lf = load_data(DATA_FILE)\n",
    "\n",
    "# Check schema and row count\n",
    "schema = lf.collect_schema()\n",
    "print(f\"Schema: {schema}\")\n",
    "\n",
    "total_rows = lf.select(pl.len()).collect().item()\n",
    "print(f\"Total rows: {total_rows:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convert-parquet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Convert CSV to Parquet for faster future loads\n",
    "def csv_to_parquet(csv_path: str, parquet_path: str = None):\n",
    "    \"\"\"\n",
    "    Convert CSV to Parquet format (streaming, memory-efficient).\n",
    "    \"\"\"\n",
    "    if parquet_path is None:\n",
    "        parquet_path = csv_path.replace('.csv', '.parquet')\n",
    "    \n",
    "    print(f\"Converting {csv_path} to {parquet_path}...\")\n",
    "    con = duckdb.connect()\n",
    "    con.execute(f\"\"\"\n",
    "        COPY (SELECT * FROM '{csv_path}') \n",
    "        TO '{parquet_path}' \n",
    "        (FORMAT PARQUET, COMPRESSION ZSTD)\n",
    "    \"\"\")\n",
    "    print(\"Done!\")\n",
    "    return parquet_path\n",
    "\n",
    "# Uncomment to convert:\n",
    "# csv_to_parquet(DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stats-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "basic-stats",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_basic_stats(lf: pl.LazyFrame) -> dict:\n",
    "    \"\"\"\n",
    "    Compute basic statistics for numeric columns.\n",
    "    \"\"\"\n",
    "    num_cols = ['theta1', 'theta2', 'theta3', 'phi01', 'phi20', 'phi21']\n",
    "    \n",
    "    stats = lf.select(\n",
    "        [pl.len().alias(\"rows\")]\n",
    "        + [pl.col(c).min().alias(f\"{c}_min\") for c in num_cols]\n",
    "        + [pl.col(c).mean().alias(f\"{c}_mean\") for c in num_cols]\n",
    "        + [pl.col(c).std(ddof=1).alias(f\"{c}_std\") for c in num_cols]\n",
    "        + [pl.col(c).max().alias(f\"{c}_max\") for c in num_cols]\n",
    "    ).collect()\n",
    "    \n",
    "    return stats\n",
    "\n",
    "stats = compute_basic_stats(lf)\n",
    "print(\"\\nNumeric Summary:\")\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlations",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_correlations(lf: pl.LazyFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute pairwise Pearson correlations between numeric columns.\n",
    "    \"\"\"\n",
    "    num_cols = ['theta1', 'theta2', 'theta3', 'phi01', 'phi20', 'phi21']\n",
    "    \n",
    "    pair_exprs = []\n",
    "    for i, a in enumerate(num_cols):\n",
    "        for b in num_cols[i+1:]:\n",
    "            pair_exprs.append(pl.corr(pl.col(a), pl.col(b)).alias(f\"{a}_vs_{b}\"))\n",
    "    \n",
    "    corr_row = lf.select(pair_exprs).collect()\n",
    "    return corr_row.transpose(include_header=True, header_name=\"pair\", column_names=[\"r\"])\n",
    "\n",
    "correlations = compute_correlations(lf)\n",
    "print(\"\\nPairwise Correlations (Pearson r):\")\n",
    "print(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sign-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Sign Classification\n",
    "\n",
    "Classify configurations by sign of key quantities:\n",
    "- d = θ₁ − θ₃ (selection differential)\n",
    "- q = φ₀₁ − φ₂₁ (inter-layer correlation differential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sign-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_by_signs(lf: pl.LazyFrame, eps: float = 1e-8) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Count configurations by sign(θ₁−θ₃) × sign(φ₀₁−φ₂₁).\n",
    "    \n",
    "    Returns 3×3 contingency table with counts and percentages.\n",
    "    \"\"\"\n",
    "    counts_dq = (\n",
    "        lf.with_columns(\n",
    "            d = pl.col(\"theta1\") - pl.col(\"theta3\"),\n",
    "            q = pl.col(\"phi01\") - pl.col(\"phi21\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            s_d = pl.when(pl.col(\"d\") > eps).then(pl.lit(\">0\"))\n",
    "                   .when(pl.col(\"d\") < -eps).then(pl.lit(\"<0\"))\n",
    "                   .otherwise(pl.lit(\"=0\")),\n",
    "            s_q = pl.when(pl.col(\"q\") > eps).then(pl.lit(\">0\"))\n",
    "                   .when(pl.col(\"q\") < -eps).then(pl.lit(\"<0\"))\n",
    "                   .otherwise(pl.lit(\"=0\")),\n",
    "        )\n",
    "        .group_by([\"s_d\", \"s_q\"])\n",
    "        .agg(pl.len().alias(\"n\"))\n",
    "        .collect()\n",
    "    )\n",
    "    \n",
    "    # Create full 3×3 grid with labels\n",
    "    labels = pl.DataFrame({\n",
    "        \"s_d\": [\">0\", \">0\", \">0\", \"=0\", \"=0\", \"=0\", \"<0\", \"<0\", \"<0\"],\n",
    "        \"s_q\": [\">0\", \"=0\", \"<0\", \">0\", \"=0\", \"<0\", \">0\", \"=0\", \"<0\"],\n",
    "    }).with_columns(\n",
    "        case_id = pl.arange(1, 10),\n",
    "        case_math = pl.concat_str([\n",
    "            pl.lit(\"θ₁−θ₃\"),\n",
    "            pl.col(\"s_d\"),\n",
    "            pl.lit(\" & φ₀₁−φ₂₁\"),\n",
    "            pl.col(\"s_q\"),\n",
    "        ], separator=\"\")\n",
    "    )\n",
    "    \n",
    "    # Join and compute percentages\n",
    "    joined = labels.join(counts_dq, on=[\"s_d\", \"s_q\"], how=\"left\").with_columns(\n",
    "        pl.col(\"n\").fill_null(0)\n",
    "    )\n",
    "    \n",
    "    total = int(joined[\"n\"].sum())\n",
    "    result = (\n",
    "        joined\n",
    "        .with_columns((pl.col(\"n\") / pl.lit(total) * 100).alias(\"percent\"))\n",
    "        .select([\"case_id\", \"s_d\", \"s_q\", \"case_math\", \"n\", \"percent\"])\n",
    "        .sort(\"case_id\")\n",
    "    )\n",
    "    \n",
    "    return result\n",
    "\n",
    "sign_table = classify_by_signs(lf, EPS)\n",
    "print(\"\\nSign Classification Table:\")\n",
    "print(sign_table)\n",
    "\n",
    "total = sign_table[\"n\"].sum()\n",
    "print(f\"\\nTotal: {total:,} | Percent sum: {sign_table['percent'].sum():.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "slopes-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Selection Gradient Analysis\n",
    "\n",
    "Compute the partial derivatives of the critical ratio r*:\n",
    "- ∂r*/∂b = φ₂₀/θ₂\n",
    "- ∂r*/∂c = (φ₀₁−φ₂₁)/θ₂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-slopes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_slope_stats(lf: pl.LazyFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute selection gradient statistics.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        lf.with_columns(\n",
    "            drdb = pl.col(\"phi20\") / pl.col(\"theta2\"),\n",
    "            drdc = (pl.col(\"phi01\") - pl.col(\"phi21\")) / pl.col(\"theta2\"),\n",
    "        )\n",
    "        .select(\n",
    "            pl.len().alias(\"n\"),\n",
    "            pl.col(\"drdb\").mean().alias(\"drdb_mean\"),\n",
    "            pl.col(\"drdb\").std(ddof=1).alias(\"drdb_std\"),\n",
    "            pl.col(\"drdc\").mean().alias(\"drdc_mean\"),\n",
    "            pl.col(\"drdc\").std(ddof=1).alias(\"drdc_std\"),\n",
    "        )\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "slope_stats = compute_slope_stats(lf)\n",
    "print(\"\\nOverall Selection Gradient Statistics:\")\n",
    "print(slope_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "slopes-by-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "def slopes_by_theta_triplet(lf: pl.LazyFrame) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Aggregate slopes by (θ₁, θ₂, θ₃) triplet.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        lf.group_by([\"theta1\", \"theta2\", \"theta3\"])\n",
    "        .agg(\n",
    "            pl.len().alias(\"n\"),\n",
    "            (pl.col(\"phi20\") / pl.col(\"theta2\")).mean().alias(\"drdb_mean\"),\n",
    "            (pl.col(\"phi20\") / pl.col(\"theta2\")).std(ddof=1).alias(\"drdb_std\"),\n",
    "            ((pl.col(\"phi01\") - pl.col(\"phi21\")) / pl.col(\"theta2\")).mean().alias(\"drdc_mean\"),\n",
    "            ((pl.col(\"phi01\") - pl.col(\"phi21\")) / pl.col(\"theta2\")).std(ddof=1).alias(\"drdc_std\"),\n",
    "        )\n",
    "        .sort([\"theta1\", \"theta2\", \"theta3\"])\n",
    "        .collect()\n",
    "    )\n",
    "\n",
    "theta_agg = slopes_by_theta_triplet(lf)\n",
    "print(f\"\\nSlopes by (θ₁, θ₂, θ₃) triplet ({theta_agg.height} groups):\")\n",
    "print(theta_agg.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "histogram-2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_slope_histogram(lf: pl.LazyFrame, sample_size: int = 100000):\n",
    "    \"\"\"\n",
    "    Create 2D histogram of selection gradients.\n",
    "    \"\"\"\n",
    "    # Sample data for histogram\n",
    "    sample = (\n",
    "        lf.with_columns(\n",
    "            drdb = pl.col(\"phi20\") / pl.col(\"theta2\"),\n",
    "            drdc = (pl.col(\"phi01\") - pl.col(\"phi21\")) / pl.col(\"theta2\"),\n",
    "        )\n",
    "        .select([\"drdb\", \"drdc\"])\n",
    "        .collect()\n",
    "        .sample(n=min(sample_size, lf.select(pl.len()).collect().item()), seed=42)\n",
    "    )\n",
    "    \n",
    "    x = sample[\"drdb\"].to_numpy()\n",
    "    y = sample[\"drdc\"].to_numpy()\n",
    "    \n",
    "    # Create histogram\n",
    "    fig, ax = plt.subplots(figsize=(8, 7))\n",
    "    \n",
    "    H, xedges, yedges = np.histogram2d(x, y, bins=100)\n",
    "    vmax = np.percentile(H, 99.5)\n",
    "    extent = [xedges.min(), xedges.max(), yedges.min(), yedges.max()]\n",
    "    \n",
    "    im = ax.imshow(H.T, origin='lower', extent=extent, aspect='auto',\n",
    "                   cmap='viridis', vmin=0, vmax=vmax, interpolation='bilinear')\n",
    "    \n",
    "    # Colorbar\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"4%\", pad=0.08)\n",
    "    fig.colorbar(im, cax=cax, label=\"Count\")\n",
    "    \n",
    "    # Labels\n",
    "    ax.set_xlabel(r\"$\\partial r^* / \\partial b$\", fontsize=12)\n",
    "    ax.set_ylabel(r\"$\\partial r^* / \\partial c$\", fontsize=12)\n",
    "    ax.set_title(\"Distribution of Selection Gradients\", fontweight='bold')\n",
    "    ax.axhline(0, color='white', lw=0.5, ls='--', alpha=0.7)\n",
    "    ax.axvline(0, color='white', lw=0.5, ls='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(\"fig_slope_histogram.png\", dpi=FIG_DPI, bbox_inches='tight', facecolor='white')\n",
    "        print(\"Saved: fig_slope_histogram.png\")\n",
    "    \n",
    "    plt.show()\n",
    "    return H, extent\n",
    "\n",
    "H, extent = plot_slope_histogram(lf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sign-barplot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sign_distribution(sign_table: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    Bar plot of sign classification distribution.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    \n",
    "    # Prepare data\n",
    "    labels = sign_table[\"case_math\"].to_list()\n",
    "    counts = sign_table[\"n\"].to_numpy()\n",
    "    percents = sign_table[\"percent\"].to_numpy()\n",
    "    \n",
    "    # Color by cooperation outcome\n",
    "    colors = []\n",
    "    for s_d, s_q in zip(sign_table[\"s_d\"].to_list(), sign_table[\"s_q\"].to_list()):\n",
    "        if s_d == \">0\":  # d > 0 favors cooperation\n",
    "            colors.append('#4DAF4A')  # Green\n",
    "        elif s_d == \"<0\" and s_q == \">0\":  # d < 0 but q > 0 can help\n",
    "            colors.append('#377EB8')  # Blue\n",
    "        else:\n",
    "            colors.append('#E41A1C')  # Red\n",
    "    \n",
    "    x = np.arange(len(labels))\n",
    "    bars = ax.bar(x, percents, color=colors, edgecolor='black', alpha=0.8)\n",
    "    \n",
    "    # Labels on bars\n",
    "    for bar, pct, cnt in zip(bars, percents, counts):\n",
    "        if pct > 0:\n",
    "            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n",
    "                    f'{pct:.1f}%\\n({cnt:,})', ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([l.replace(' & ', '\\n') for l in labels], fontsize=9)\n",
    "    ax.set_ylabel(\"Percentage of Configurations\")\n",
    "    ax.set_title(\"Distribution by Sign of (θ₁−θ₃) and (φ₀₁−φ₂₁)\", fontweight='bold')\n",
    "    \n",
    "    # Legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#4DAF4A', label='d>0 (cooperation favored)'),\n",
    "        Patch(facecolor='#377EB8', label='d<0, q>0 (conditional)'),\n",
    "        Patch(facecolor='#E41A1C', label='Other'),\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(\"fig_sign_distribution.png\", dpi=FIG_DPI, bbox_inches='tight', facecolor='white')\n",
    "        print(\"Saved: fig_sign_distribution.png\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_sign_distribution(sign_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theta-scatter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_theta_vs_phi(lf: pl.LazyFrame, sample_size: int = 50000):\n",
    "    \"\"\"\n",
    "    Scatter plots of theta vs phi relationships.\n",
    "    \"\"\"\n",
    "    sample = lf.collect().sample(n=min(sample_size, lf.select(pl.len()).collect().item()), seed=42)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "    \n",
    "    # θ₂ vs φ₂₀\n",
    "    ax = axes[0]\n",
    "    ax.scatter(sample[\"theta2\"].to_numpy(), sample[\"phi20\"].to_numpy(), \n",
    "               alpha=0.1, s=1, c='#377EB8')\n",
    "    ax.set_xlabel(r\"$\\theta_2$\")\n",
    "    ax.set_ylabel(r\"$\\phi_{20}$\")\n",
    "    ax.set_title(r\"$\\theta_2$ vs $\\phi_{20}$\")\n",
    "    ax.axhline(0, color='gray', lw=0.5, ls='--')\n",
    "    ax.axvline(0, color='gray', lw=0.5, ls='--')\n",
    "    \n",
    "    # θ₁−θ₃ vs φ₀₁−φ₂₁\n",
    "    ax = axes[1]\n",
    "    d = sample[\"theta1\"].to_numpy() - sample[\"theta3\"].to_numpy()\n",
    "    q = sample[\"phi01\"].to_numpy() - sample[\"phi21\"].to_numpy()\n",
    "    ax.scatter(d, q, alpha=0.1, s=1, c='#E41A1C')\n",
    "    ax.set_xlabel(r\"$\\theta_1 - \\theta_3$\")\n",
    "    ax.set_ylabel(r\"$\\phi_{01} - \\phi_{21}$\")\n",
    "    ax.set_title(r\"Selection differential vs inter-layer\")\n",
    "    ax.axhline(0, color='gray', lw=0.5, ls='--')\n",
    "    ax.axvline(0, color='gray', lw=0.5, ls='--')\n",
    "    \n",
    "    # φ₂₀ vs φ₂₁\n",
    "    ax = axes[2]\n",
    "    ax.scatter(sample[\"phi20\"].to_numpy(), sample[\"phi21\"].to_numpy(),\n",
    "               alpha=0.1, s=1, c='#4DAF4A')\n",
    "    ax.set_xlabel(r\"$\\phi_{20}$\")\n",
    "    ax.set_ylabel(r\"$\\phi_{21}$\")\n",
    "    ax.set_title(r\"Inter-layer correlations\")\n",
    "    ax.axhline(0, color='gray', lw=0.5, ls='--')\n",
    "    ax.axvline(0, color='gray', lw=0.5, ls='--')\n",
    "    # Add y=x line\n",
    "    lims = [min(ax.get_xlim()[0], ax.get_ylim()[0]), \n",
    "            max(ax.get_xlim()[1], ax.get_ylim()[1])]\n",
    "    ax.plot(lims, lims, 'k--', alpha=0.3, lw=1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if SAVE_FIGURES:\n",
    "        plt.savefig(\"fig_theta_phi_scatter.png\", dpi=FIG_DPI, bbox_inches='tight', facecolor='white')\n",
    "        print(\"Saved: fig_theta_phi_scatter.png\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "plot_theta_vs_phi(lf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(lf: pl.LazyFrame, sign_table: pl.DataFrame):\n",
    "    \"\"\"\n",
    "    Generate summary statistics report.\n",
    "    \"\"\"\n",
    "    total = sign_table[\"n\"].sum()\n",
    "    \n",
    "    # Cooperation favored: d > 0\n",
    "    d_pos = sign_table.filter(pl.col(\"s_d\") == \">0\")[\"n\"].sum()\n",
    "    d_pos_pct = d_pos / total * 100\n",
    "    \n",
    "    # d < 0 but q > 0 (can still favor cooperation)\n",
    "    d_neg_q_pos = sign_table.filter(\n",
    "        (pl.col(\"s_d\") == \"<0\") & (pl.col(\"s_q\") == \">0\")\n",
    "    )[\"n\"].sum()\n",
    "    d_neg_q_pos_pct = d_neg_q_pos / total * 100\n",
    "    \n",
    "    # Potentially favorable total\n",
    "    favorable = d_pos + d_neg_q_pos\n",
    "    favorable_pct = favorable / total * 100\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ENUMERATION SUMMARY REPORT\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\\nTotal unique configurations: {total:,}\")\n",
    "    print(f\"\\nCooperation Analysis:\")\n",
    "    print(f\"  θ₁−θ₃ > 0 (directly favored):     {d_pos:>10,} ({d_pos_pct:>5.1f}%)\")\n",
    "    print(f\"  θ₁−θ₃ < 0 & φ₀₁−φ₂₁ > 0 (cond.): {d_neg_q_pos:>10,} ({d_neg_q_pos_pct:>5.1f}%)\")\n",
    "    print(f\"  ─────────────────────────────────────────────────\")\n",
    "    print(f\"  Potentially favorable:            {favorable:>10,} ({favorable_pct:>5.1f}%)\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "generate_summary(lf, sign_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "export-header",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "export",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export sign classification table\n",
    "sign_table.write_csv(\"sign_classification.csv\")\n",
    "print(\"Saved: sign_classification.csv\")\n",
    "\n",
    "# Export theta aggregation\n",
    "theta_agg.write_csv(\"theta_aggregation.csv\")\n",
    "print(\"Saved: theta_aggregation.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
